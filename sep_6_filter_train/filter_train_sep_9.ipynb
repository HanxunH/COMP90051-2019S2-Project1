{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPositiveNegativeNum(dataframe):\n",
    "    total_len = len(dataframe)\n",
    "    positive_num = sum(dataframe.pair_result)\n",
    "    negative_num = total_len - positive_num\n",
    "    return (positive_num, negative_num)\n",
    "\n",
    "def getIndexFromTopByLabel(label, top, dataframe):\n",
    "    temp = dataframe.where(dataframe.pair_result[:,2] == label).dropna()\n",
    "    return list(temp.index)[:top]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version = \"v1_5\"\n",
    "# train_set_path = '../data/{0}/train_set_{0}.txt'.format(version)\n",
    "# train_dataframe = pd.read_csv(train_set_path, sep='\\t', header=None)\n",
    "# sorted_train_dataframe = train_dataframe.sort_values(0).reset_index(drop=True)\n",
    "# unique_id_list = sorted_train_dataframe[0].unique()\n",
    "# train_sentence_num_dict = train_dataframe.iloc[:,0].value_counts()\n",
    "# train_sentence_id_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# output_train_setence_id_dict_file_path = \"../data/{0}/train_set_dict_{0}.pkl\".format(version)\n",
    "# for user_id in unique_id_list:\n",
    "#     candidate_df = sorted_train_dataframe.where(sorted_train_dataframe[0] == user_id).dropna()\n",
    "#     train_sentence_id_dict[user_id] = list(candidate_df[1])\n",
    "\n",
    "# with open(output_train_setence_id_dict_file_path, 'wb') as pickle_file:\n",
    "#     pickle.dump(train_sentence_id_dict, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_train_sentence_dict_path = \"../data/{0}/train_set_dict_{0}.pkl\".format(version)\n",
    "# train_sentence_id_dict = None\n",
    "# with open(load_train_sentence_dict_path, 'rb') as pickle_file:\n",
    "#     train_sentence_id_dict = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Start to process split 5\n",
      "[INFO] Start to process split 6\n",
      "CPU times: user 5min 9s, sys: 7.39 s, total: 5min 17s\n",
      "Wall time: 5min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "output_path_prefix = \"../data/split_2019_09_08_lemonbear_epoch2_k_100\"\n",
    "output_filtered_split_file_dir = \"{0}/filtered_split_result\".format(output_path_prefix)\n",
    "split_num_list = [5,6]\n",
    "# split_num_list = range(4,7)\n",
    "k = 100\n",
    "top = 20\n",
    "for split_num in split_num_list:\n",
    "    split_file_path = \"{0}/split_result/split_pair_{1}.txt\".format(output_path_prefix, split_num)\n",
    "    split_file = pd.read_csv(split_file_path, sep=\"\\t\")\n",
    "    if not os.path.exists(output_filtered_split_file_dir):\n",
    "        print(\"[ERROR] Directory not exists: {0}\".format(output_filtered_split_file_dir))\n",
    "        break\n",
    "    print(\"[INFO] Start to process split {0}\".format(split_num))\n",
    "    filtered_index = []\n",
    "    for i in range(0, len(split_file), k):\n",
    "        sub_split = split_file.iloc[i:i+k, :]\n",
    "        first_top_sub_split = split_file.iloc[i:i+top, :]\n",
    "        first_positive, first_negative = getPositiveNegativeNum(first_top_sub_split)\n",
    "        all_positive, all_negative = getPositiveNegativeNum(sub_split)\n",
    "        if first_negative == 0:\n",
    "            continue\n",
    "        select_num = min(first_negative, all_positive)\n",
    "        if select_num == 0:\n",
    "            continue\n",
    "        first_negative_index = getIndexFromTopByLabel(0, select_num, first_top_sub_split)\n",
    "        all_positive_index = getIndexFromTopByLabel(1, select_num, sub_split)\n",
    "        filtered_index += first_negative_index\n",
    "        filtered_index += all_positive_index\n",
    "    if 0 == len(filtered_index):\n",
    "        print(\"[WARNING] Filtered num = 0 in split {0}\".format(split_num))\n",
    "        continue\n",
    "    output_file_path = \"{0}/filtered_split_pair_{1}.csv\".format(output_filtered_split_file_dir, split_num)\n",
    "    output_df = split_file.iloc[filtered_index].reset_index(drop=True)\n",
    "    output_df.to_csv(output_file_path, index=False, sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
