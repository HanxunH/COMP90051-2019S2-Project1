{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embedding feature of training and dev set\n",
    "# Load original dataset\n",
    "k = 1000\n",
    "train_feature_path = \"train_feature.npy\"\n",
    "train_set_path = \"../data/v1_5/train_set_v1_5.txt\"\n",
    "dev_feature_path = \"dev_feature.npy\"\n",
    "dev_set_path = \"../data/v1_5/dev_set_v1_5.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Extract sentence and label of training and dev set\n",
    "train_feature = np.load(train_feature_path)\n",
    "train_set = pd.read_csv(train_set_path, sep='\\t', header=None)\n",
    "train_set = np.array(train_set)\n",
    "train_sentence = train_set[:,1]\n",
    "train_label = (train_set[:,0]).astype('int')\n",
    "split_set = pd.read_csv(dev_set_path, sep='\\t', header=None)\n",
    "split_set = np.array(split_set)\n",
    "split_sentence = split_set[:,1]\n",
    "split_label = (split_set[:,0]).astype('int')\n",
    "print(\"[SUCCESS] Loaded data\")\n",
    "\n",
    "split_feature = np.load(dev_feature_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Fit data to KNN Classifier\n",
    "print(\"[INFO] Fit knn model\")\n",
    "knn_clf = KNeighborsClassifier(n_jobs=-1, n_neighbors=k, weights=\"distance\")\n",
    "knn_clf.fit(train_feature, train_label)\n",
    "print(\"[SUCCESS] Successfully fitted knn model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Finding k neighbors using KNN Classifier fitted above\n",
    "print(\"[INFO] Finding kneighbors\")\n",
    "k_neighbors_list = knn_clf.kneighbors(X=split_feature, return_distance=False)\n",
    "print(\"[SUCCESS] Successfully Finded kneighbors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSplitPairDataFrame(true_sentence_list,\n",
    "                          candidate_sentence_list,\n",
    "                          candidate_label_true_false,\n",
    "                          true_label_list,\n",
    "                          candidate_label_list):\n",
    "    return pd.DataFrame({'true_sentence':true_sentence_list,\n",
    "                         'candidate_sentence':candidate_sentence_list,\n",
    "                         'pair_result':candidate_label_true_false,\n",
    "                         'true_label':true_label_list,\n",
    "                         'candidate_label':candidate_label_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# output K candidates pair file, and save in output_pair_file_path\n",
    "output_pair_file_path = \"split_pair_dev_k_{0}.txt\".format(k)\n",
    "true_label_list = split_label.repeat(k)\n",
    "true_sentence_list = split_sentence.repeat(k)\n",
    "\n",
    "candidate_index_list = k_neighbors_list.ravel()\n",
    "candidate_label_list = train_label[candidate_index_list]\n",
    "candidate_label_true_false = (candidate_label_list == true_label_list).astype('int')\n",
    "candidate_sentence_list = train_sentence[candidate_index_list]\n",
    "split_data = getSplitPairDataFrame(true_sentence_list,\n",
    "                                   candidate_sentence_list,\n",
    "                                   candidate_label_true_false,\n",
    "                                   true_label_list,\n",
    "                                   candidate_label_list)\n",
    "split_data.to_csv(output_pair_file_path, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1000\n",
    "split_pair_path = \"../data/split_600w_2epoch/split_pair_dev_k_600w_2epoch_{0}.txt\".format(k)\n",
    "split_data = pd.read_csv(split_pair_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.58 s, sys: 312 ms, total: 1.89 s\n",
      "Wall time: 1.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "total_len = len(split_data)\n",
    "unique_len = int(total_len/k)\n",
    "original_shape = (unique_len, k)\n",
    "true_sentence = np.array(split_data.true_sentence).reshape(original_shape)\n",
    "candidate_sentence = np.array(split_data.candidate_sentence).reshape(original_shape)\n",
    "pair_result = np.array(split_data.pair_result).reshape(original_shape)\n",
    "true_label = np.array(split_data.true_label).reshape(original_shape)\n",
    "candidate_label = np.array(split_data.candidate_label).reshape(original_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall of knn k_top = 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.49361702127659574"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get k_top recall of KNN Classifier, k_top <= k.\n",
    "k_top = 100\n",
    "print(\"Recall of knn k_top = {0}\".format(k_top))\n",
    "np.mean(np.max(pair_result[:,:k_top], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save k_top Split for probability file\n",
    "k_top_pair_file_path = \"../data/split_600w_2epoch/k_top_pair_file_{0}_of_{1}.csv\".format(k_top, k)\n",
    "k_top_split_data = getSplitPairDataFrame(true_sentence[:,:k_top].ravel(),\n",
    "                                         candidate_sentence[:,:k_top].ravel(),\n",
    "                                         pair_result[:,:k_top].ravel(),\n",
    "                                         true_label[:,:k_top].ravel(),\n",
    "                                         candidate_label[:,:k_top].ravel())\n",
    "k_top_split_data.to_csv(k_top_pair_file_path, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from probability file, get k_top candidates from knn k\n",
    "# The k_top probablity is computed by the first model\n",
    "probability_file_path = \"../data/split_600w_2epoch/dev_results_k_{0}_of_k_{1}.csv\".format(k_top, k)\n",
    "\n",
    "probability_file = pd.read_csv(probability_file_path, sep='\\t',header=None).iloc[:,1]\n",
    "probability_mat = np.array(probability_file).reshape(original_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSortedByProbability(original_shape, candidate_mat, probability_mat):\n",
    "    sorted_candidate_mat = np.zeros((original_shape)).astype('int')\n",
    "    sorted_probability_mat = np.zeros((original_shape))\n",
    "    for i in range(original_shape[0]):\n",
    "        sorted_index = probability_mat[i].argsort()[::-1]\n",
    "        sorted_candidate_mat[i] = candidate_mat[i, sorted_index]\n",
    "        sorted_probability_mat[i] = probability_mat[i, sorted_index] \n",
    "    return (sorted_candidate_mat, sorted_probability_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Sort according to probability, descending\n",
    "sorted_candidate_label, sorted_probability_mat = \\\n",
    "        getSortedCandidateLabel(original_shape,\n",
    "                                candidate_label,\n",
    "                                probability_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFilteredLabel(weights, label_list):\n",
    "    unique_label = np.unique(label_list)\n",
    "    final_weights = np.zeros((unique_label.shape))\n",
    "    for i, label in enumerate(unique_label):\n",
    "        label_index = (label == label_list)\n",
    "        final_weights[i] = sum(weights[label_index])\n",
    "    sorted_index = final_weights.argsort()[::-1]\n",
    "    return unique_label[sorted_index[0]]\n",
    "\n",
    "def getWeightedLabel(weights, labels, threshold, filter=True):\n",
    "    if filter:\n",
    "        if weights[0] <= threshold:\n",
    "            return labels[0]\n",
    "        filtered_index = (weights > threshold)\n",
    "        return getFilteredLabel(weights[filtered_index], labels[filtered_index])\n",
    "    else:\n",
    "        return getFilteredLabel(weights, labels)\n",
    "\n",
    "def computeAccuracy(predicted, true_label):\n",
    "    accuracy = accuracy_score(true_label, predicted)\n",
    "    print(\"accuracy: {0}\".format(accuracy))\n",
    "    \n",
    "def getOutput(mat, index, top):\n",
    "    return mat[index, :top].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Get top candidates from probability matrix, according to the probablility\n",
    "# And compute the recall of \"top\" candidate with \"top\" probability\n",
    "top = 20\n",
    "probability_threshold = 0.5\n",
    "new_candidate_list = np.zeros((unique_len, 1)).astype('int')\n",
    "for i in range(unique_len):\n",
    "    new_candidate_list[i] = \\\n",
    "            getWeightedLabel(\n",
    "                    sorted_probability_mat[i,:top],\n",
    "                    sorted_candidate_label[i,:top],\n",
    "                    probability_threshold, False)\n",
    "computeAccuracy(new_candidate_list, true_label[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Store the positive pair(Recall pair) which contains true label in \"top\" candidates\n",
    "output_positive_pair_file_path = \"data/split_600w_2epoch/positive_pair_dev_600w_2epoch_top_{0}_from_k_top_{1}_k_{2}_.txt\".format(top, k_top, top)\n",
    "positive_index = (np.max(sorted_pair_result[:,:top], axis=1) == 1)\n",
    "output_true_sentence = getOutput(true_sentence, positive_index, top)\n",
    "output_candidate_sentence =  getOutput(sorted_candidate_sentence, positive_index, top)\n",
    "output_pair_result = getOutput(sorted_pair_result, positive_index, top)\n",
    "output_true_label = getOutput(true_label, positive_index, top)\n",
    "output_candidate_label = getOutput(sorted_candidate_label, positive_index, top)\n",
    "positive_pair_df = getSplitPairDataFrame(output_true_sentence,\n",
    "                                         output_candidate_sentence,\n",
    "                                         output_pair_result,\n",
    "                                         output_true_label,\n",
    "                                         output_candidate_label)                         \n",
    "positive_pair_df.to_csv(output_positive_pair_file_path, sep='\\t', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_total_len = len(positive_pair_df)\n",
    "positive_unique_len = int(total_len/top)\n",
    "positive_original_shape = (unique_len, top)\n",
    "positive_true_label = np.array(positive_pair_df.true_label).reshape(positive_original_shape)\n",
    "positive_pair_result = np.array(positive_pair_df.pair_result).reshape(positive_original_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The k_top probablity is computed by the first model\n",
    "positive_probability_file_path = \"../data/split_600w_2epoch/positive_pair_dev_results_600w_2epoch_top_{0}_from_k_top_{1}_k_{2}_.txt\".format(top, k_top, top)\n",
    "\n",
    "positive_probability_file = pd.read_csv(positive_probability_file_path, sep='\\t',header=None).iloc[:,1]\n",
    "positive_probability_mat = np.array(positive_probability_file).reshape(positive_original_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Sort according to probability, descending\n",
    "sorted_positive_pair_result, sorted_positive_probability_mat = \\\n",
    "        getSortedCandidateLabel(positive_original_shape,\n",
    "                                positive_pair_result,\n",
    "                                positive_probability_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_top = 1\n",
    "print(\"Accuracy: \")\n",
    "np.mean(np.max(sorted_positive_pair_result[:,:accuracy_top], axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
