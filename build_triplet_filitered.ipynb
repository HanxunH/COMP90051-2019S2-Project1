{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def build_data_set(input_file_path, out_file_path, total_nums_of_rows=200000, dataset_list=[]):\n",
    "    print(input_file_path)\n",
    "    train_dict = collections.defaultdict(list)\n",
    "    with open(input_file_path, encoding='utf-8') as tsvfile:\n",
    "        reader = tsvfile.readlines()\n",
    "        for i, row in enumerate(reader):\n",
    "            row = row.strip().split(\"\\t\")\n",
    "            id = int(row[0])\n",
    "            instance = row[1]\n",
    "            train_dict[id].append(instance)\n",
    "        print(\"Total rows: %d\" % i)\n",
    "    print(\"Total ids: %d\" % len(train_dict))\n",
    "    df = pd.DataFrame()\n",
    "    while len(dataset_list) < total_nums_of_rows:\n",
    "        positive_id = random.choice(list(train_dict.keys()))\n",
    "        negative_id = random.choice(list(train_dict.keys()))\n",
    "        positive_sentence = train_dict[positive_id]\n",
    "        negative_sentence = train_dict[negative_id]\n",
    "\n",
    "        anchor = random.choice(positive_sentence)\n",
    "        positive = random.choice(positive_sentence)\n",
    "        negative = random.choice(negative_sentence)\n",
    "\n",
    "        if anchor is None or positive is None or negative is None:\n",
    "            raise('Error')\n",
    "\n",
    "        dataset_list.append([anchor, positive, negative])\n",
    "\n",
    "    df = pd.DataFrame((dataset_list))\n",
    "    print(df.head())\n",
    "    print(len(df))\n",
    "    df.to_csv(out_file_path, index=False, sep='\\t', header=None)\n",
    "    print(out_file_path, ' Saved!')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_file_path = 'data/v7/filter_v7/filtered_split_pair_all_siamese_bert_base_cased_epoch2.csv'\n",
    "filtered_pairs = pd.read_csv(filtered_file_path, sep='\\t')\n",
    "trian_dict = collections.defaultdict(list)\n",
    "for index, row in filtered_pairs.iterrows():\n",
    "    if row[0] not in trian_dict:\n",
    "        trian_dict[row[0]] = [[], []]\n",
    "\n",
    "    if row[2] == 1:\n",
    "        # Positive Pair\n",
    "        trian_dict[row[0]][0].append(row[1])\n",
    "    else:\n",
    "        # Negative Pair\n",
    "        trian_dict[row[0]][1].append(row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583136\n"
     ]
    }
   ],
   "source": [
    "filitered_triplet = []\n",
    "for key in trian_dict:\n",
    "    positive_list = trian_dict[key][0]\n",
    "    negative_list = trian_dict[key][1]\n",
    "    if len(positive_list) != len(negative_list):\n",
    "        raise('Error')\n",
    "    for positive, negative in zip(positive_list, negative_list):\n",
    "        filitered_triplet.append([key, positive, negative])\n",
    "\n",
    "print(len(filitered_triplet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/v7/train_set_v1_7.txt\n",
      "Total rows: 292747\n",
      "Total ids: 9268\n",
      "                                                   0  \\\n",
      "0  #2009faillist the New Jersey Nets, they should...   \n",
      "1  #2009faillist the New Jersey Nets, they should...   \n",
      "2  #2009faillist the New Jersey Nets, they should...   \n",
      "3  #2009faillist the New Jersey Nets, they should...   \n",
      "4  Major did you get Jake to unblock me? I have s...   \n",
      "\n",
      "                                                   1  \\\n",
      "0    #cheatingexcuses I was taking one for the team.   \n",
      "1  I cant believe the New Jersey Nets one a fucki...   \n",
      "2  If he is driving an 89 Civic with 22 inch rims...   \n",
      "3  #2009faillist guys with lip rings. Stop trying...   \n",
      "4  I tweeted a funny joke at you when you were si...   \n",
      "\n",
      "                                                   2  \n",
      "0  #ihatewhen the #WhiteSox lose to rival teams l...  \n",
      "1  #MW2 for the \"boo\". Can someone tell me why th...  \n",
      "2  He should make that # famous. If I was in the ...  \n",
      "3  #thingsilike seeing the Lakers beat the shit o...  \n",
      "4  jehovah witness. I won't change ur mind, u won...  \n",
      "1200000\n",
      "data/v7/triplet_train_filitered.csv  Saved!\n"
     ]
    }
   ],
   "source": [
    "build_data_set(input_file_path=\"data/v7/train_set_v1_7.txt\",\n",
    "               out_file_path=\"data/v7/triplet_train_filitered.csv\",\n",
    "               total_nums_of_rows=1200000,\n",
    "               dataset_list=filitered_triplet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
