{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "path = 'paired_sentences_dev.csv'\n",
    "\n",
    "dataset = pd.read_csv(path, sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u got your own club now!?</td>\n",
       "      <td>OMG okay i will...GOSH #twitter do better.... ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Sidewalk\" by Starlight Mints from \"Drowaton\"</td>\n",
       "      <td>i might check it out</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ehhh not really. cuz he got right back up ther...</td>\n",
       "      <td>I own 4 Apple computers. Life is great.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Patulugin mo na siya, Pacman!</td>\n",
       "      <td>Fuck the Yankees, not the AL East.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>J-E-T-S... Jets, Jets, Jets!! :)</td>\n",
       "      <td>On the Sunday menu: reading scripts then sport...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0                          u got your own club now!?   \n",
       "1      \"Sidewalk\" by Starlight Mints from \"Drowaton\"   \n",
       "2  ehhh not really. cuz he got right back up ther...   \n",
       "3                      Patulugin mo na siya, Pacman!   \n",
       "4                   J-E-T-S... Jets, Jets, Jets!! :)   \n",
       "\n",
       "                                                   1  2  \n",
       "0  OMG okay i will...GOSH #twitter do better.... ...  1  \n",
       "1                               i might check it out  0  \n",
       "2            I own 4 Apple computers. Life is great.  0  \n",
       "3                 Fuck the Yankees, not the AL East.  1  \n",
       "4  On the Sunday menu: reading scripts then sport...  1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_0_encode = np.load(\"set_0_encode.npy\")\n",
    "set_1_encode = np.load(\"set_1_encode.npy\")\n",
    "train_x = np.concatenate((set_0_encode,set_1_encode),axis=1)\n",
    "train_y = np.array(dataset[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_binary = to_categorical(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 768)               1180416   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 1538      \n",
      "=================================================================\n",
      "Total params: 1,181,954\n",
      "Trainable params: 1,181,954\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=768, activation='relu', input_dim=train_x.shape[1]))\n",
    "# model.add(Dense(units=50, activation='relu', input_dim=x_train.shape[1]))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(units=2, activation='softmax'))\n",
    "# optimizer = Adam(lr=0.01)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "# SVG(model_to_dot(model).create(prog='dot', format='svg'))\n",
    "\n",
    "# callbacks\n",
    "filepath=\"best_weights_tough_head.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "earlyStopping = EarlyStopping(monitor='val_acc', patience=2, verbose=0, mode='auto')\n",
    "\n",
    "callbacks_list = [checkpoint, earlyStopping]\n",
    "\n",
    "# model.fit(x=x_train, y=y_train, batch_size=32, epochs=50, validation_split=0.1, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 360000 samples, validate on 40000 samples\n",
      "Epoch 1/50\n",
      "360000/360000 [==============================] - 27s 75us/step - loss: 0.6025 - acc: 0.6645 - val_loss: 0.5797 - val_acc: 0.6838\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.68385, saving model to best_weights_tough_head.hdf5\n",
      "Epoch 2/50\n",
      "360000/360000 [==============================] - 26s 73us/step - loss: 0.5704 - acc: 0.6944 - val_loss: 0.5716 - val_acc: 0.6935\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.68385 to 0.69350, saving model to best_weights_tough_head.hdf5\n",
      "Epoch 3/50\n",
      "360000/360000 [==============================] - 27s 76us/step - loss: 0.5548 - acc: 0.7053 - val_loss: 0.5630 - val_acc: 0.6995\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.69350 to 0.69947, saving model to best_weights_tough_head.hdf5\n",
      "Epoch 4/50\n",
      "360000/360000 [==============================] - 27s 76us/step - loss: 0.5434 - acc: 0.7147 - val_loss: 0.5635 - val_acc: 0.6969\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.69947\n",
      "Epoch 5/50\n",
      "360000/360000 [==============================] - 26s 73us/step - loss: 0.5322 - acc: 0.7226 - val_loss: 0.5692 - val_acc: 0.6974\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.69947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa85c5c3f28>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_x, y=y_binary, batch_size=32, epochs=50, validation_split=0.1, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
