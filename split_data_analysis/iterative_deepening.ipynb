{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = 100\n",
    "split_pair_path = \"../data/split_dev/split_pair_dev_k_{0}.txt\".format(top)\n",
    "train_data_path = \"../data/split_dev/train_set.txt\"\n",
    "dev_data_path = \"../data/split_dev/dev_set_v1_4.txt\"\n",
    "\n",
    "\n",
    "train_data = pd.read_csv(train_data_path, sep='\\t', header=None)\n",
    "train_label = np.array(train_data.iloc[:,0]).astype('int')\n",
    "dev_data = pd.read_csv(dev_data_path, sep='\\t', header=None)\n",
    "dev_label = np.array(dev_data.iloc[:,0]).astype('int')\n",
    "split_data = pd.read_csv(split_pair_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive:negative = 177881:3104819\n"
     ]
    }
   ],
   "source": [
    "split_yes_no_list = np.array(split_data.iloc[:,2])\n",
    "print(\"positive:negative = {0}:{1}\".format(sum(split_yes_no_list==1), sum(split_yes_no_list==0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: 16574/32827=0.5049\n",
      "CPU times: user 93.4 ms, sys: 137 Âµs, total: 93.5 ms\n",
      "Wall time: 193 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "total_single_split_num = int(len(split_yes_no_list)/top)\n",
    "counter = 0\n",
    "index_list = []\n",
    "for i in range(0, len(split_yes_no_list), top):\n",
    "    single_split = split_yes_no_list[i:(i+top)]\n",
    "    if 1 in single_split:\n",
    "        #new_train_data = new_train_data.append(split_data.iloc[i:(i+top),:])\n",
    "        index_list.append(i)\n",
    "        counter += 1\n",
    "print(\"recall: {0}/{1}={2:.4f}\".format(counter, total_single_split_num, (counter/total_single_split_num)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "new_train_data = pd.DataFrame()\n",
    "for i in range(0, len(split_yes_no_list), top):\n",
    "    single_split = split_yes_no_list[i:(i+top)]\n",
    "    if 1 in single_split:\n",
    "        new_train_data = new_train_data.append(split_data.iloc[i:(i+top),:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 1/ (sum(new_train_data.iloc[:,2]==1)/sum(new_train_data.iloc[:,2]==0))\n",
    "print(\"positive:negative = {0}:{1}\".format(sum(new_train_data.iloc[:,2]==1), sum(new_train_data.iloc[:,2]==0)))\n",
    "print(\"ratio: {0}\".format(1/ratio))\n",
    "print(\"ratio: {0}\".format(ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_pair_path = \"../data/split_dev/new_split_pair_dev_k_{0}.txt\".format(top)\n",
    "\n",
    "new_train_data.to_csv(split_pair_path, sep='\\t', index=False)\n",
    "#new_train_data = pd.read_csv(split_pair_path, sep='\\t')\n",
    "new_train_data = new_train_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from probability file, get top k candidates\n",
    "probability_file_path = \"../data/split_dev/dev_results_k_100.csv\"\n",
    "\n",
    "probability_file = pd.read_csv(probability_file_path, sep='\\t',header=None).iloc[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.4 ms, sys: 0 ns, total: 29.4 ms\n",
      "Wall time: 8.44 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "total_len = len(new_train_data)\n",
    "unique_len = int(total_len/top)\n",
    "index_set = set(range(unique_len))\n",
    "true_label = np.array(new_train_data.true_label).reshape(unique_len, top)[:,1]\n",
    "candidate_label_mat = np.array(new_train_data.candidate_label).reshape(unique_len, top)\n",
    "probability_mat = np.array(probability_file).reshape(unique_len, top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIndexedList(target_mat, index_list):\n",
    "    return target_mat[np.arange(len(target_mat)), index_list]\n",
    "\n",
    "def getMaxProbabilityList(probability_mat, candidate_label_mat):\n",
    "    max_probability_index = np.argmax(probability_mat, axis=1)\n",
    "    max_probability_list = getIndexedList(probability_mat, max_probability_index)\n",
    "    max_label_list = getIndexedList(candidate_label_mat, max_probability_index)\n",
    "    return max_probability_list, max_label_list\n",
    "\n",
    "def computeAccuracy(predicted, true_label):\n",
    "    accuracy = accuracy_score(true_label, predicted)\n",
    "    print(\"accuracy: {0}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10116\n",
      "accuracy: 0.842131277184658\n",
      "728\n",
      "accuracy: 0.49313186813186816\n",
      "448\n",
      "accuracy: 0.44642857142857145\n",
      "261\n",
      "accuracy: 0.4482758620689655\n",
      "5021\n",
      "accuracy: 0.6116206105949077\n",
      "CPU times: user 19 ms, sys: 0 ns, total: 19 ms\n",
      "Wall time: 18.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Iterative Deepening\n",
    "max_top = 100\n",
    "top_step_size = 20\n",
    "new_candidate_list = np.zeros((unique_len,1)).astype('int')\n",
    "index_list = np.array(list(index_set))\n",
    "probability_threshold = 0.5\n",
    "for mini_top in range(top_step_size, max_top, top_step_size):\n",
    "    max_probability_list, max_label_list = \\\n",
    "            getMaxProbabilityList( \\\n",
    "                probability_mat[index_list, :mini_top],\n",
    "                candidate_label_mat[index_list, :mini_top])\n",
    "\n",
    "#     mini_probability_mat = probability_mat[index_list, :mini_top]\n",
    "#     mini_label_mat = candidate_label_mat[index_list, :mini_top]\n",
    "#     max_probability_index = np.argmax(mini_probability_mat)\n",
    "#     max_probability_list = getIndexedList(mini_probability_mat, max_probability_index)\n",
    "#     max_label_list = getIndexedList(mini_label_mat, max_probability_index)\n",
    "   \n",
    "    filted_probablity_index = (max_probability_list > probability_threshold)\n",
    "    new_index_list = index_list[filted_probablity_index]\n",
    "    temp_max_candidate_list = max_label_list[filted_probablity_index]\n",
    "    temp_max_candidate_list = temp_max_candidate_list.reshape((len(temp_max_candidate_list),1))\n",
    "    new_candidate_list[new_index_list] = temp_max_candidate_list\n",
    "\n",
    "    #new_candidate_list[index_list][filted_probablity_index] = temp_max_candidate_list\n",
    "    #new_candidate_list[index_list] = max_label_list.reshape((len(max_label_list),1))\n",
    "    #print(np.sum(new_candidate_list == 0))\n",
    "    print(len(new_index_list))\n",
    "    computeAccuracy(temp_max_candidate_list, true_label[new_index_list])\n",
    "    index_list = index_list[np.logical_not(filted_probablity_index)]\n",
    "    \n",
    "\n",
    "max_probability_list, max_label_list = \\\n",
    "        getMaxProbabilityList(\n",
    "            probability_mat[index_list, :max_top],\n",
    "            candidate_label_mat[index_list, :max_top])\n",
    "print(len(index_list))\n",
    "new_candidate_list[index_list] = max_label_list.reshape((len(max_label_list), 1))\n",
    "computeAccuracy(new_candidate_list, true_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6103535658259925\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2129,  262,  420, ..., 5098, 4935, 7549])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11553"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
